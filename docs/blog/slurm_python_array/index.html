<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Parallelizing Python scripts with Slurm arrays | Maximilian Pierzyna</title>
<meta name="keywords" content="">
<meta name="description" content="Sometimes, you have a simple Python script that iteratively performs a lot of similar tasks.
Think of a script, for example, that post-processes a large number of raw files, where each execution can happen independently.
These scripts can be easily parallized with Slurm arrays.
Submitting a job as a Slurm array is like asking Slurm to run a for-loop. You will have access to an extra environment variable, the $SLURM_ARRAY_TASK_ID, which is the iteration variable of your loop.">
<meta name="author" content="">
<link rel="canonical" href="https://maximilian-pierzyna.de/blog/slurm_python_array/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css" integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://maximilian-pierzyna.de/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://maximilian-pierzyna.de/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://maximilian-pierzyna.de/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://maximilian-pierzyna.de/apple-touch-icon.png">
<link rel="mask-icon" href="https://maximilian-pierzyna.de/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://maximilian-pierzyna.de/blog/slurm_python_array/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><link rel="stylesheet" href="https://maximilian-pierzyna.de/css/halfmoon/halfmoon_hm-11.css"><link rel="stylesheet" href="https://maximilian-pierzyna.de/css/manual.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha512-MV7K8+y+gLIBoVD59lQIYicR65iaqukzvf/nwasF0nqhPay5w/9lJmVM2hMDcnK1OnMGCdVK+iQrJ7lzPJQd1w==" crossorigin="anonymous" referrerpolicy="no-referrer" />
<meta property="og:url" content="https://maximilian-pierzyna.de/blog/slurm_python_array/">
  <meta property="og:site_name" content="Maximilian Pierzyna">
  <meta property="og:title" content="Parallelizing Python scripts with Slurm arrays">
  <meta property="og:description" content="Sometimes, you have a simple Python script that iteratively performs a lot of similar tasks. Think of a script, for example, that post-processes a large number of raw files, where each execution can happen independently. These scripts can be easily parallized with Slurm arrays.
Submitting a job as a Slurm array is like asking Slurm to run a for-loop. You will have access to an extra environment variable, the $SLURM_ARRAY_TASK_ID, which is the iteration variable of your loop.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Parallelizing Python scripts with Slurm arrays">
<meta name="twitter:description" content="Sometimes, you have a simple Python script that iteratively performs a lot of similar tasks.
Think of a script, for example, that post-processes a large number of raw files, where each execution can happen independently.
These scripts can be easily parallized with Slurm arrays.
Submitting a job as a Slurm array is like asking Slurm to run a for-loop. You will have access to an extra environment variable, the $SLURM_ARRAY_TASK_ID, which is the iteration variable of your loop.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blog",
      "item": "https://maximilian-pierzyna.de/blog/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Parallelizing Python scripts with Slurm arrays",
      "item": "https://maximilian-pierzyna.de/blog/slurm_python_array/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Parallelizing Python scripts with Slurm arrays",
  "name": "Parallelizing Python scripts with Slurm arrays",
  "description": "Sometimes, you have a simple Python script that iteratively performs a lot of similar tasks. Think of a script, for example, that post-processes a large number of raw files, where each execution can happen independently. These scripts can be easily parallized with Slurm arrays.\nSubmitting a job as a Slurm array is like asking Slurm to run a for-loop. You will have access to an extra environment variable, the $SLURM_ARRAY_TASK_ID, which is the iteration variable of your loop.\n",
  "keywords": [
    
  ],
  "articleBody": "Sometimes, you have a simple Python script that iteratively performs a lot of similar tasks. Think of a script, for example, that post-processes a large number of raw files, where each execution can happen independently. These scripts can be easily parallized with Slurm arrays.\nSubmitting a job as a Slurm array is like asking Slurm to run a for-loop. You will have access to an extra environment variable, the $SLURM_ARRAY_TASK_ID, which is the iteration variable of your loop.\nContent of this article: Simple sequential for-loop with sbatch script Making Slurm run the loop A note on numpy Simple sequential for-loop with sbatch script Let’s look at a sequential example first. Assume you have the following simple Python script, which processes a bunch of files.\n## process.py FILES = [ \"data_01.nc\", \"data_02.nc\", \"data_03.nc\", \"data_04.nc\", ] # Pythonic for-loop for f in FILES: process(f) # Alternative for-loop, more common in C-style languages for i in range(len(FILES)): process(FILES[i]) We can run this script by creating a simple accompanying Slurm job script.\n## process.job.sh #SBATCH --job-name=processing #SBATCH --ntasks=8 #SBATCH --mem-per-cpu=4000 # Run the script python process.py Finally, the job is submitted with sbatch process.job.sh.\nThe disadvantage of this method is that we do not utilize the fact that each loop execution is independent of the previous one or the one after. In other words, all files could be processed in parallel by running the Python script multiple times. This is where Slurm can help.\nMaking Slurm run the loop We can easily convert such a script to a Slurm array by moving the for-loop “outside of the script”. First, our script needs to take command line arguments, so we can iterate from the outside:\n## process.py import argparse FILES = [ \"data_01.nc\", \"data_02.nc\", \"data_03.nc\", \"data_04.nc\", ] # Parse arguments parser = argparse.ArgumentParser() parser.add_argument(\"i\", help=\"Number of file in FILES to process\") args = parser.parse_args() # Run post-processing for i-th file process(FILES[args.i]) The i-th file (e.g., the third file) can now be processed by running the following command:\npython process.py 3 Next, the job script needs a small modification. Instead of providing a fixed number as argument to the script like above, we provide the variable $SLURM_ARRAY_TASK_ID. This variable will be populated by Slurm in the final step, so the updated job script looks like this:\n## process.job.sh #SBATCH --job-name=processing #SBATCH --ntasks=8 #SBATCH --mem-per-cpu=4000 # Run the script python process.py $SLURM_ARRAY_TASK_ID Finally, we need to tell Slurm to run the loop for us by submitting this job as an array:\nsbatch --array=0-3 process.job.sh This will automatically submit the script four times where the $SLURM_ARRAY_TASK_ID is increased from 0 to 3. In other words, Slurm will run\npython process.py 0 python process.py 1 python process.py 2 python process.py 3 Each job will receive the ressources specified in the job script. This method can be applied very widely and not just for file processing. Assume, you want to train a machine learning model with a pre-defined number of settings. You can list these settings in a list similar to FILES and pass the settings as arguments to a train() function similar to the process() call in this example. Sometimes, it is also needed to run the same experiment in a randomized fashion (e.g., Monte Carlo simulations or training of a machine learning ensemble). In that case, you can simply provide the i argument, i.e., the $SLURM_ARRAY_TASK_ID, as random seed for your random number generator. As a result, each script will have its own chain of random numbers while still being reproducible through a fixed seed.\nOn a more practical note, if submitting hunderts of jobs through an array, it might be polite to limit the number of jobs that can run in parallel. In principle, the scheduler (Slurm) will not run more jobs than it has physical resources available. However, if you share a partition with your department, you might still exhaust all the resources available to your colleagues – so, none of them can run jobs anymore. To avoid this, we can, for example, process 100 files but only 10 of them in parallel by running\nsbatch --array=0-99%10 process.job.sh The %10 in the array definition defines the number of allowed parallel jobs, here, ten.\nA note on numpy Numpy is a popular scientific computing library in Python. It is highly optimized and will run many operations in parallel by itself. However, numpy sometimes (always?) does not detect when it is run on a high-performance computer (HPC) where it only has access to a subset of resources. Say, a compute node has 64 cores, but you submit a job requesting only 8 cores. Numpy might still assume that it can use all 64 cores when, in fact, it cannot. The result might be a slow down because numpy starts 64 parallel activities (threads), which have to compete for the eight “real slots” of parallel execution. To avoid this issue, we can tell numpy to only use as many cores as the job requested.\nInstead of simply running your Python script like above…\n## process.job.sh #SBATCH --job-name=processing #SBATCH --ntasks=8 #SBATCH --mem-per-cpu=4000 # Run the script python process.py $SLURM_ARRAY_TASK_ID … we modify it like this:\n## process.job.sh #SBATCH --job-name=processing #SBATCH --ntasks=8 #SBATCH --mem-per-cpu=4000 # Run the script OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK \\ OPENBLAS_NUM_THREADS=$SLURM_CPUS_PER_TASK \\ MKL_NUM_THREADS=$SLURM_CPUS_PER_TASK \\ VECLIB_MAXIMUM_THREADS=$SLURM_CPUS_PER_TASK \\ NUMEXPR_NUM_THREADS=$SLURM_CPUS_PER_TASK \\ python process.py $SLURM_ARRAY_TASK_ID Don’t get scared by this slightly intimidating call of python. Prefixing the python command like this tells the different underlying high-performance parts of Python (OpenMP, OpenBLAS, MathKernelLibrary MKL, VecLib, …) to only use $SLURM_CPUS_PER_TASK. That variable will get populated by Slurm with what is given in the script, here, 8 cores.\n",
  "wordCount" : "931",
  "inLanguage": "en",
  "datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://maximilian-pierzyna.de/blog/slurm_python_array/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Maximilian Pierzyna",
    "logo": {
      "@type": "ImageObject",
      "url": "https://maximilian-pierzyna.de/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://maximilian-pierzyna.de/" accesskey="h" title="Maximilian Pierzyna (Alt + H)">Maximilian Pierzyna</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://maximilian-pierzyna.de/blog/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://maximilian-pierzyna.de/research/" title="Research">
                    <span>Research</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Parallelizing Python scripts with Slurm arrays
    </h1>
    <div class="post-meta">

</div>
  </header> 
  <div class="post-content"><p>Sometimes, you have a simple Python script that iteratively performs a lot of similar tasks.
Think of a script, for example, that post-processes a large number of raw files, where each execution can happen independently.
These scripts can be easily parallized with Slurm arrays.</p>
<p>Submitting a job as a Slurm array is like asking Slurm to run a for-loop. You will have access to an extra environment variable, the <code>$SLURM_ARRAY_TASK_ID</code>, which is the iteration variable of your loop.</p>
<p>Content of this article:
<nav id="TableOfContents">
  <ul>
    <li><a href="#simple-sequential-for-loop-with-sbatch-script">Simple sequential for-loop with sbatch script</a></li>
    <li><a href="#making-slurm-run-the-loop">Making Slurm run the loop</a></li>
    <li><a href="#a-note-on-numpy">A note on numpy</a></li>
  </ul>
</nav></p>
<h2 id="simple-sequential-for-loop-with-sbatch-script">Simple sequential for-loop with sbatch script<a hidden class="anchor" aria-hidden="true" href="#simple-sequential-for-loop-with-sbatch-script">#</a></h2>
<p>Let&rsquo;s look at a sequential example first. Assume you have the following simple Python script, which processes a bunch of files.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">## process.py</span>
</span></span><span style="display:flex;"><span>FILES <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;data_01.nc&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;data_02.nc&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;data_03.nc&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;data_04.nc&#34;</span>,
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Pythonic for-loop</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> f <span style="color:#f92672">in</span> FILES:
</span></span><span style="display:flex;"><span>    process(f)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Alternative for-loop, more common in C-style languages</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(FILES)):
</span></span><span style="display:flex;"><span>    process(FILES[i])
</span></span></code></pre></div><p>We can run this script by creating a simple accompanying Slurm job script.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e">## process.job.sh</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --job-name=processing</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --ntasks=8</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --mem-per-cpu=4000</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Run the script</span>
</span></span><span style="display:flex;"><span>python process.py
</span></span></code></pre></div><p>Finally, the job is submitted with <code>sbatch process.job.sh</code>.</p>
<p>The disadvantage of this method is that we do not utilize the fact that each loop execution is independent of the previous one or the one after.
In other words, all files could be processed in parallel by running the Python script multiple times.
This is where Slurm can help.</p>
<h2 id="making-slurm-run-the-loop">Making Slurm run the loop<a hidden class="anchor" aria-hidden="true" href="#making-slurm-run-the-loop">#</a></h2>
<p>We can easily convert such a script to a Slurm array by moving the for-loop &ldquo;outside of the script&rdquo;.
First, our script needs to take command line arguments, so we can iterate from the outside:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">## process.py</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> argparse
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>FILES <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;data_01.nc&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;data_02.nc&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;data_03.nc&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;data_04.nc&#34;</span>,
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Parse arguments</span>
</span></span><span style="display:flex;"><span>parser <span style="color:#f92672">=</span> argparse<span style="color:#f92672">.</span>ArgumentParser()
</span></span><span style="display:flex;"><span>parser<span style="color:#f92672">.</span>add_argument(<span style="color:#e6db74">&#34;i&#34;</span>, help<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Number of file in FILES to process&#34;</span>)
</span></span><span style="display:flex;"><span>args <span style="color:#f92672">=</span> parser<span style="color:#f92672">.</span>parse_args()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Run post-processing for i-th file</span>
</span></span><span style="display:flex;"><span>process(FILES[args<span style="color:#f92672">.</span>i])
</span></span></code></pre></div><p>The i-th file (e.g., the third file) can now be processed by running the following command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>python process.py <span style="color:#ae81ff">3</span>
</span></span></code></pre></div><p>Next, the job script needs a small modification. Instead of providing a fixed number as argument to the script like above, we provide the variable <code>$SLURM_ARRAY_TASK_ID</code>. This variable will be populated by Slurm in the final step, so the updated job script looks like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e">## process.job.sh</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --job-name=processing</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --ntasks=8</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --mem-per-cpu=4000</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Run the script</span>
</span></span><span style="display:flex;"><span>python process.py $SLURM_ARRAY_TASK_ID
</span></span></code></pre></div><p>Finally, we need to tell Slurm to run the loop for us by submitting this job as an array:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sbatch --array<span style="color:#f92672">=</span>0-3 process.job.sh
</span></span></code></pre></div><p>This will automatically submit the script four times where the <code>$SLURM_ARRAY_TASK_ID</code> is increased from 0 to 3.
In other words, Slurm will run</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>python process.py <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>python process.py <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>python process.py <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>python process.py <span style="color:#ae81ff">3</span>
</span></span></code></pre></div><p>Each job will receive the ressources specified in the job script.
This method can be applied very widely and not just for file processing.
Assume, you want to train a machine learning model with a pre-defined number of settings.
You can list these settings in a list similar to <code>FILES</code> and pass the settings as arguments to a <code>train()</code> function similar to the <code>process()</code> call in this example.
Sometimes, it is also needed to run the same experiment in a randomized fashion (e.g., Monte Carlo simulations or training of a machine learning ensemble).
In that case, you can simply provide the <code>i</code> argument, i.e., the <code>$SLURM_ARRAY_TASK_ID</code>, as random seed for your random number generator.
As a result, each script will have its own chain of random numbers while still being reproducible through a fixed seed.</p>
<p>On a more practical note, if submitting hunderts of jobs through an array, it might be polite to limit the number of jobs that can run in parallel.
In principle, the scheduler (Slurm) will not run more jobs than it has physical resources available.
However, if you share a partition with your department, you might still exhaust all the resources available to your colleagues &ndash; so, none of them can run jobs anymore.
To avoid this, we can, for example, process 100 files but only 10 of them in parallel by running</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sbatch --array<span style="color:#f92672">=</span>0-99%10 process.job.sh
</span></span></code></pre></div><p>The <code>%10</code> in the array definition defines the number of allowed parallel jobs, here, ten.</p>
<h2 id="a-note-on-numpy">A note on numpy<a hidden class="anchor" aria-hidden="true" href="#a-note-on-numpy">#</a></h2>
<p>Numpy is a popular scientific computing library in Python. It is highly optimized and will run many operations in parallel by itself.
However, numpy sometimes (always?) does not detect when it is run on a high-performance computer (HPC) where it only has access to a subset of resources.
Say, a compute node has 64 cores, but you submit a job requesting only 8 cores.
Numpy might still assume that it can use all 64 cores when, in fact, it cannot.
The result might be a slow down because numpy starts 64 parallel activities (threads), which have to compete for the eight &ldquo;real slots&rdquo; of parallel execution.
To avoid this issue, we can tell numpy to only use as many cores as the job requested.</p>
<p>Instead of simply running your Python script like above&hellip;</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e">## process.job.sh</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --job-name=processing</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --ntasks=8</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --mem-per-cpu=4000</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Run the script</span>
</span></span><span style="display:flex;"><span>python process.py $SLURM_ARRAY_TASK_ID
</span></span></code></pre></div><p>&hellip; we modify it like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e">## process.job.sh</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --job-name=processing</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --ntasks=8</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --mem-per-cpu=4000</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Run the script</span>
</span></span><span style="display:flex;"><span>OMP_NUM_THREADS<span style="color:#f92672">=</span>$SLURM_CPUS_PER_TASK <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>OPENBLAS_NUM_THREADS<span style="color:#f92672">=</span>$SLURM_CPUS_PER_TASK <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>MKL_NUM_THREADS<span style="color:#f92672">=</span>$SLURM_CPUS_PER_TASK <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>VECLIB_MAXIMUM_THREADS<span style="color:#f92672">=</span>$SLURM_CPUS_PER_TASK <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>NUMEXPR_NUM_THREADS<span style="color:#f92672">=</span>$SLURM_CPUS_PER_TASK <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>python process.py $SLURM_ARRAY_TASK_ID
</span></span></code></pre></div><p>Don&rsquo;t get scared by this slightly intimidating call of <code>python</code>.
Prefixing the <code>python</code> command like this tells the different underlying high-performance parts of Python (OpenMP, OpenBLAS, MathKernelLibrary MKL, VecLib, &hellip;) to only use <code>$SLURM_CPUS_PER_TASK</code>.
That variable will get populated by Slurm with what is given in the script, here, 8 cores.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://maximilian-pierzyna.de/">Maximilian Pierzyna</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a><script src="https://maximilian-pierzyna.de/js/custom.js"></script>
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>



<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
